%-------------------------------------------------------------------------------
%	SECTION TITLE
%-------------------------------------------------------------------------------
\cvsection{Consulting}

\newcommand*{\logo}[2]{\raisebox{-0.2em}{\includegraphics[height=1em]{#2}}\hspace{0.25em}#1}
\newcommand*{\logoonly}[1]{\raisebox{-0.2em}{\includegraphics[height=1em]{#1}}}

\tcbset{on line,
    boxrule=0pt, boxsep=4pt, left=0pt,right=0pt,top=0pt,bottom=0pt,
    colframe=white,colback={lightgray!15}
}

\newcommand*{\tagx}[1]{
    \tcbox{\color{graytext}#1}
}

%-------------------------------------------------------------------------------
%	CONTENT
%-------------------------------------------------------------------------------
\begin{cventries}
    \cventry
    {\tagx{scala} \tagx{play} \tagx{mongodb} \tagx{api} \tagx{cqrs} \tagx{kafka}}
    {\logo{Groupe Foyer}{../../../images/foyer}$\sqbig$scala\,|\,staff engineer}
    {Luxembourg}
    {Oct 2024 - present}
    {}
%    {At Foyer, Luxembourg's Largest Insurer, I design and develop backend APIs using Scala, Kafka, and CQRS, with a strong focus on code quality, scalability, and maintainability. Lead key backend initiatives and advocate for technical excellence across the team.}
    {
        \begin{cvitems}
            \item{Developed new apis leveraging cqrs, scala, and kafka to support marketing initiatives.}
            \item{Championed test-driven development (tdd) and clean code practices; acted as a key voice for engineering best practices.}
            \item{Modernized legacy systems by migrating rest apis to contemporary architectures using cqrs and event sourcing patterns.}
            \item{Led technical design and implementation of integrations with third-party tax assessment providers.}
        \end{cvitems}
    }

%---------------------------------------------------------


    \cventry
    {\tagx{rust} \tagx{scala} \tagx{http4s} \tagx{go} \tagx{kinesis} \tagx{openid} \tagx{opentelemetry} \tagx{sso} \tagx{databricks}}
    {\logo{Disney streaming}{../../../images/disney}$\sqbig$scala\,|\,rust\,|\,staff engineer}
    {Luxembourg}
    {Oct 2022 - Sept 2024}
    {}
    %{Designed and implemented SSO and OpenID Connect architectures to optimize authentication flows across platforms and devices. Led performance and scalability enhancements in Identity Provider (IdP) systems.}
    {
        \begin{cvitems}
            \item{Architected and deployed single sign-on user authentication using openid connect.}
            \item{Engineered performance improvements in idp services, scaling user account handling from 350m to 800m with zero downtime.}
            \item{Participated in cross-functional systems designs and teams: security, mobile, web, to integrate authentication components.}
            \item{Developed lambda and kinesis tooling in rust. Integrated globalprotect vpn support for linux users using go.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{rust} \tagx{scala} \tagx{kafka} \tagx{etl} \tagx{kafka-streams} \tagx{ksql} \tagx{spark}}
    {\logo{Depop}{../../../images/depop.jpg}$\sqbig$scala\,|\,data engineer}
    {Luxembourg}
    {Mar 2022 - Sept 2022}
    {}
    %{At Depop, the leading second-hand marketplace for emerging fashion designers in the UK and US, I was re-engaged to drive the design and implementation of streaming data strategies and real-time APIs, ensuring seamless integration with mobile applications.}
    {
        \begin{cvitems}
            \item{Led the creation of enriched, unified datasets by overseeing the use of ksql, kafka streams, and spark streaming pipelines.}
            \item{Directed the architecture of materialized streamed datasets with sub-15-minute views (delta tables) for olap queries, leveraging dbt, spark, and databricks.}
            \item{Managed the enhancement of safety, reliability, and observability across deployment pipelines and applications.}
        \end{cvitems}
    }

%---------------------------------------------------------

    \cventry
    {\tagx{scala} \tagx{java} \tagx{etl} \tagx{api} \tagx{grpc} \tagx{akka-streams} \tagx{websockets} \tagx{iot}}
    {\logo{Zego}{../../../images/zego.jpg}$\sqbig$scala\,|\,data engineer}
    {Luxembourg}
    {Nov 2021 - Aug 2022}
    {}
    %{At Zego, an innovative driver insurance company disrupting the market with on-demand coverage, I led the design and deployment of Flink and Akka Streams-based ingestion processors, incorporating machine learning models to assess risk levels and coverage appetite.}
    {
        \begin{cvitems}
            \item{Integrated third-party vehicle (iot) and insurance data via rest apis, grpc, and websockets, utilising kinesis and akka streams for seamless data processing.}
            \item{Orchestrated ci/cd pipelines using kubernetes, argocd, and buildkite, ensuring automated deployment and continuous integration.}
            \item{Integrated iot data with tableau and snowflake, feeding into a data lake for comprehensive data analysis and reporting.}
        \end{cvitems}
    }

%---------------------------------------------------------

    \cventry
    {\tagx{scala} \tagx{kafka} \tagx{etl} \tagx{ksql} \tagx{kafka-streams} \tagx{confluent}}
    {\logo{Slice}{../../../images/slice}$\sqbig$scala\,|\,data engineer}
    {Luxembourg}
    {Apr 2021 - Oct 2021}
    {}
    %{At Slice, a company empowering independent pizza vendors to grow their online presence, I led the architecture and implementation of streaming pipelines to provide real-time sales and revenue feedback to vendors.}
    {
        \begin{cvitems}
            \item{Led the migration to a high-throughput, stream-oriented data processing architecture, enhancing data handling capabilities.}
            \item{Integrated schema registries and schema evolution processes into the data lake.}
            \item{Designed and implemented ci/cd pipelines for streaming data (kafka\,streams, spark\,streaming, ksqldb), integrating from databricks to confluent.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{scala} \tagx{kafka} \tagx{etl} \tagx{api} \tagx{emr} \tagx{spring boot} \tagx{kafka-streams}}
    {\logo{Compare The Market}{../../../images/ctm}$\sqbig$scala\,|\,data engineer}
    {London}
    {Jan 2020 - Mar 2021}
    {}
    %{At Compare The Market, a leading comparison platform aggregating insurance quotes, I was brought in to optimize Kafka clusters and stream processors, as well as develop systems for ingesting and providing real-time pricing data from third-party feeds.}
    {
        \begin{cvitems}
            \item{Designed etl ci/cd pipelines for streaming data flows using spring boot, kafka streams, akka streams, and spark streaming.}
            \item{Led the design and strategy for a streaming infrastructure, presenting the architecture at design forums (adf) and to key stakeholders.}
            \item{Developed data governance and retention strategies for the data lake.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{scala} \tagx{kafka} \tagx{etl} \tagx{kafka-streams} \tagx{ksql} \tagx{redshift} \tagx{rabbitmq}}
    {\logo{Depop}{../../../images/depop.jpg}$\sqbig$scala\,|\,data engineer}
    {London}
    {June 2019 - Dec 2019}
    {}
    %{At Depop, I led the data engineering team in implementing streaming data pipelines to ensure real-time synchronization of a Redshift cluster, driving data consistency and operational efficiency.}
    {
        \begin{cvitems}
            \item{Directed the design and deployment of aws redshift and rabbitmq data ingestion pipelines, utilising kinesis and akka streams to streamline data processing.}
            %\item{Coordinated and coached team members around streaming data processes and technologies.}
            \item{Led research and evaluation of emerging technologies (e.g., kafka streams, samza), identifying optimisation opportunities and presenting strategic proposals and recommendations for improving data pipeline performance.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{scala} \tagx{kinesis} \tagx{etl} \tagx{api} \tagx{emr} \tagx{kafka-streams}}
    {\logo{The Guardian}{../../../images/guardian}$\sqbig$scala\,|\,data engineer}
    {London}
    {Oct 2018 - May 2019}
    {}
    %{At The Guardian, a leading UK newspaper, I designed and implemented systems capable of handling hundreds of millions of events, ingesting data from Kinesis streams into Elasticsearch via Logstash, and utilizing Kibana for monitoring and observability. I also led the design and deployment of Spark Streaming processors to extract real-time insights.}
    {
        \begin{cvitems}
            \item{Developed and implemented spark etl pipelines on aws emr, processing reader revenue and subscription datasets to drive data-driven decision-making.}
            \item{Designed and built alternative streaming pipelines using msk, eks, and kafka streams to enhance data flow and processing efficiency.}
            \item{Architected and established a data lake and catalog around emr and athena, ensuring streamlined data access and analytics.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{scala} \tagx{kafka} \tagx{etl} \tagx{cloudera} \tagx{kerberos} \tagx{hive} \tagx{kafka-streams}}
    {\logo{Sainsbury's}{../../../images/sainsburys.jpg}$\sqbig$scala\,|\,data engineer}
    {London}
    {Dec 2017 - Sep 2018}
    {}
    %{At Sainsbury’s, the largest supermarket chain in the UK, I designed the architecture and developed the platform and pipelines to enhance the loyalty program, enabling real-time rewards and refunds for customers.}
    {
        \begin{cvitems}
            \item{Replaced batch-based data processing with a streaming pipeline, reducing data processing time to under 4 seconds.}
            \item{Led the architecture and deployment of kafka clusters (apache and cloudera), along with kms and kerberos for secure data handling.}
            %\item{Design and implementation of kafka-streams, kafka-connect, and schema-registry etls on ecs. Data analytics using hive, spark and zeppelin.}
            \item{Implemented gdpr-compliant stream processors, utilising data tokenisation and encryption to ensure pii protection and regulatory compliance.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{scala} \tagx{java} \tagx{akka} \tagx{api} \tagx{etl} \tagx{spring boot} \tagx{akka-streams}}
    {\logo{Home Office (HMPO \& IPT)}{../../../images/ho}$\sqbig$scala engineer}
    {London}
    {June 2016 - Nov 2017}
    {}
    %{At HMPO and IPT, government bodies responsible for border security and immigration policies, I worked on sensitive areas such as asylum claims and passport issuance. I implemented secure systems where data security, auditability, and accountability were crucial to the integrity of the processes I designed.}
    {
        \begin{cvitems}
            \item{Led the development of hmpo’s online passport renewal portal and the security design of data ingestion processes.}
            \item{Implemented resilient data transfer layers using spring boot, akka streams, and akka persistence on kubernetes, ensuring high availability and data integrity across systems.}
            %\item{Api contract testing with swagger and gatling.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{scala} \tagx{java} \tagx{akka} \tagx{fullstack} \tagx{etl} \tagx{fullstack}}
    {\logo{HMRC (Valuation Office Agency)}{../../../images/voa}$\sqbig$scala engineer}
    {London}
    {Nov 2015 - May 2016}
    {}
    %{At the VOA, a government agency responsible for setting and enforcing tax rates for private and business properties across the UK, I led the redesign of the UI and data input processing, integrating data flows with legacy back-end systems.}
    {
        \begin{cvitems}
            \item{Designed and implemented an akka wrapper around a legacy web application using akka streams. Presented the design for stakeholder approval.}
            \item{Delivered a government-compliant solution that provided a nationwide platform for council tax and business rates collection, ensuring seamless functionality and compliance.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{scala} \tagx{java} \tagx{akka} \tagx{play} \tagx{rabbitmq}}
    {\logo{Home Office (Border Force)}{../../../images/ho}$\sqbig$java\,|\,scala engineer}
    {London}
    {Mar 2014 - Oct 2015}
    {}
    %{Border Force is a government agency responsible for securing the UK borders. I created a real-time flight arrival prediction system to forecast airport queue times and staff requirements at the gates.}
    {
        \begin{cvitems}
            \item{Built a flight arrival prediction engine and incorporated resiliency and recovery processes using akka and rabbitmq.}
            %\item{Designed and implemented internal tools for case worker application management using play.}
        \end{cvitems}
    }

%---------------------------------------------------------
    \cventry
    {full stack java/scala engineer}
    {\logo{Capco}{../../../images/capco}}
    {London}
    {Sep 2013 - Dec 2013}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {full stack jee/grails engineer}
    {\logo{News UK (News International)}{../../../images/newsuk}}
    {London}
    {Nov 2012 - June 2013}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {full stack jee/grails engineer}
    {\logo{HappyInc Ltd {\textit (now Blow Ltd)}}{../../../images/blowltd}}
    {London}
    {Jul 2012 - Sep 2012}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {full stack jee/grails engineer}
    {\logo{BSkyB (Sky Group)}{../../../images/sky}}
    {London}
    {Aug 2011 - June 2012}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {senior jee engineer}
    {\logo{DMC Digital}{../../../images/dealchecker}}
    {London}
    {Dec 2010 - Jul 2011}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {senior jee engineer}
    {\logo{ITHR}{../../../images/ithr}}
    {London}
    {Oct 2010 - Nov 2010}
    {}
    {}
\end{cventries}
