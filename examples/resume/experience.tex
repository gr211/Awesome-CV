%-------------------------------------------------------------------------------
%	SECTION TITLE
%-------------------------------------------------------------------------------
\cvsection{Consulting}

\newcommand*{\logo}[2]{\raisebox{-0.2em}{\includegraphics[height=1em]{#2}}\hspace{0.25em}#1}
\newcommand*{\logoonly}[1]{\raisebox{-0.2em}{\includegraphics[height=1em]{#1}}}

\tcbset{on line,
    boxrule=0pt, boxsep=4pt, left=0pt,right=0pt,top=0pt,bottom=0pt,
    colframe=white,colback={lightgray!15}
}

\newcommand*{\tagx}[1]{
    \tcbox{\color{graytext}#1}
}

%-------------------------------------------------------------------------------
%	CONTENT
%-------------------------------------------------------------------------------
\begin{cventries}
    \cventry
    {\tagx{play} \tagx{mongodb} \tagx{cqrs} \tagx{kafka} \tagx{k8s}}
    {\logo{Groupe Foyer}{../../../images/foyer}$\sqbig$scala\,|\,staff engineer}
    {Luxembourg}
    {Oct 2024 - present}
    {}
%    {At Foyer, Luxembourg's Largest Insurer, I design and develop backend APIs using Scala, Kafka, and CQRS, with a strong focus on code quality, scalability, and maintainability. Lead key backend initiatives and advocate for technical excellence across the team.}
    {
        Championed test-driven development (tdd) and clean code practices; acted as a key voice for engineering best practices.\newline
    Led technical design and implementation of integrations with third-party tax assessment providers.
    }
%---------------------------------------------------------


    \cventry
    {\tagx{http4s} \tagx{kinesis} \tagx{openid} \tagx{opentelemetry} \tagx{sso} \tagx{databricks}}
    {\logo{Disney streaming}{../../../images/disney}$\sqbig$scala\,|\,rust\,|\,staff engineer}
    {Luxembourg}
    {Oct 2022 - Sept 2024}
    {}
    %{Designed and implemented SSO and OpenID Connect architectures to optimize authentication flows across platforms and devices. Led performance and scalability enhancements in Identity Provider (IdP) systems.}
    {
        Engineered performance improvements in idp services, scaling user account handling from 350m to 800m with zero downtime.
    \newline
    Participated in cross-functional systems designs and teams: security, mobile, web, to integrate authentication components.
    }

%---------------------------------------------------------
    \cventry
    {\tagx{kafka} \tagx{airflow} \tagx{kafka-streams} \tagx{ksql} \tagx{spark} \tagx{databricks} \tagx{dbt} \tagx{eks}}
    {\logo{Depop}{../../../images/depop.jpg}$\sqbig$scala\,|\,go\,|\,\,rust\,|\,data engineer}
    {Luxembourg}
    {Mar 2022 - Sept 2022}
    {}
    %{At Depop, the leading second-hand marketplace for emerging fashion designers in the UK and US, I was re-engaged to drive the design and implementation of streaming data strategies and real-time APIs, ensuring seamless integration with mobile applications.}
    {
        Led the creation of enriched, unified datasets by overseeing the use of ksql, kafka streams, and spark streaming pipelines.
    \newline
    %\item{Directed the architecture of materialized streamed datasets with sub-15-minute views (delta tables) for olap warehouses.}
    Managed the enhancement of safety, reliability, and observability across deployment pipelines and applications.
    }

%---------------------------------------------------------

    \cventry
    {\tagx{etl} \tagx{protobuf} \tagx{grpc} \tagx{akka-streams} \tagx{websockets} \tagx{iot}}
    {\logo{Zego}{../../../images/zego.jpg}$\sqbig$scala\,|\,data engineer}
    {Luxembourg}
    {Nov 2021 - Aug 2022}
    {}
    %{At Zego, an innovative driver insurance company disrupting the market with on-demand coverage, I led the design and deployment of Flink and Akka Streams-based ingestion processors, incorporating machine learning models to assess risk levels and coverage appetite.}
    {
    %\item{Integrated third-party vehicle (iot) and insurance data via rest apis, grpc, and websockets, using kinesis and akka-streams.}
        Orchestrated ci/cd pipelines using kubernetes, argocd, and buildkite, ensuring automated deployment and continuous integration.
    \newline
    Integrated iot data with tableau and snowflake, feeding into a data lake for comprehensive data analysis and reporting.
    }

%---------------------------------------------------------

    \cventry
    {\tagx{kafka} \tagx{ksql} \tagx{kafka-streams} \tagx{confluent} \tagx{databricks} \tagx{yarn}}
    {\logo{Slice}{../../../images/slice}$\sqbig$scala\,|\,data engineer}
    {London}
    {Apr 2021 - Oct 2021}
    {}
    %{At Slice, a company empowering independent pizza vendors to grow their online presence, I led the architecture and implementation of streaming pipelines to provide real-time sales and revenue feedback to vendors.}
    {
        Led the migration to a high-throughput, stream-oriented data processing architecture, enhancing data handling capabilities.
    %\item{Integrated schema registries and schema evolution processes into the data lake.}
    \newline
    Designed and implemented ci/cd pipelines for streaming data using kafka-streams, spark-streaming and ksqldb.
    }

%---------------------------------------------------------
    \cventry
    {\tagx{kafka} \tagx{nifi} \tagx{emr} \tagx{spring boot} \tagx{kafka-streams}}
    {\logo{Compare The Market}{../../../images/ctm}$\sqbig$scala\,|\,data engineer}
    {London}
    {Jan 2020 - Mar 2021}
    {}
    %{At Compare The Market, a leading comparison platform aggregating insurance quotes, I was brought in to optimize Kafka clusters and stream processors, as well as develop systems for ingesting and providing real-time pricing data from third-party feeds.}
    {
    %\item{Designed etl ci/cd pipelines for streaming data flows using spring boot, kafka streams, akka streams, and spark streaming.}
        Led the design and strategy for a streaming infrastructure, presenting the architecture at design forums (adf) and to key stakeholders.
    \newline
    Developed data governance and retention strategies for the data lake.
    }

%---------------------------------------------------------
    \cventry
    {\tagx{kafka} \tagx{airflow} \tagx{kafka-streams} \tagx{ksql} \tagx{redshift} \tagx{rabbitmq}}
    {\logo{Depop}{../../../images/depop.jpg}$\sqbig$scala\,|\,data engineer}
    {London}
    {June 2019 - Dec 2019}
    {}
    %{At Depop, I led the data engineering team in implementing streaming data pipelines to ensure real-time synchronization of a Redshift cluster, driving data consistency and operational efficiency.}
    {
        Directed the design and deployment of aws redshift and rabbitmq data ingestion pipelines, using kinesis and kafka-streams.
    \newline
    %\item{Coordinated and coached team members around streaming data processes and technologies.}
    Led research and evaluation labs, identifying optimisation opportunities and presenting strategic proposals and recommendations.
    }

%---------------------------------------------------------
    \cventry
    {\tagx{kinesis} \tagx{emr} \tagx{kafka-streams} \tagx{k8s} }
    {\logo{The Guardian}{../../../images/guardian}$\sqbig$scala\,|\,data engineer}
    {London}
    {Oct 2018 - May 2019}
    {}
    %{At The Guardian, a leading UK newspaper, I designed and implemented systems capable of handling hundreds of millions of events, ingesting data from Kinesis streams into Elasticsearch via Logstash, and utilizing Kibana for monitoring and observability. I also led the design and deployment of Spark Streaming processors to extract real-time insights.}
    {
        Built spark etl pipelines on aws emr, processing reader revenue and subscription datasets to drive data-driven decision-making.
    \newline
    %\item{Designed and built alternative streaming pipelines using msk, eks, and kafka streams to enhance data flow and processing efficiency.}
    Architected and established a data lake and catalog around emr and athena, ensuring streamlined data access and analytics.
    }

%---------------------------------------------------------
    \cventry
    {\tagx{kafka} \tagx{ecs} \tagx{cloudera} \tagx{kerberos} \tagx{hive} \tagx{kafka-streams}}
    {\logo{Sainsbury's}{../../../images/sainsburys.jpg}$\sqbig$scala\,|\,data engineer}
    {London}
    {Dec 2017 - Sep 2018}
    {}
    %{At Sainsbury’s, the largest supermarket chain in the UK, I designed the architecture and developed the platform and pipelines to enhance the loyalty program, enabling real-time rewards and refunds for customers.}
    {
    %\item{Replaced batch-based data processing with a streaming pipeline, reducing data processing time to under 4 seconds.}
    %\item{Led the architecture and deployment of kafka clusters (apache and cloudera), along with kms and kerberos for secure data handling.}
    %\item{Design and implementation of kafka-streams, kafka-connect, and schema-registry etls on ecs. Data analytics using hive, spark and zeppelin.}
        Implemented gdpr-compliant stream processors, using data tokenisation and encryption to ensure pii protection and regulatory compliance.
    }

%---------------------------------------------------------
    \cventry
    {\tagx{akka-persistence} \tagx{spring-boot} \tagx{akka-streams}}
    {\logo{Home Office (HMPO \& IPT)}{../../../images/ho}$\sqbig$scala engineer}
    {London}
    {June 2016 - Nov 2017}
    {}
    %{At HMPO and IPT, government bodies responsible for border security and immigration policies, I worked on sensitive areas such as asylum claims and passport issuance. I implemented secure systems where data security, auditability, and accountability were crucial to the integrity of the processes I designed.}
    {
        Led the development of hmpo’s online passport renewal portal and the security design of data ingestion processes.
    %\item{Implemented ha data transfer layers using spring boot, akka streams, and akka persistence on kubernetes.}
    %\item{Api contract testing with swagger and gatling.}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{akka-streams} \tagx{play}}
    {\logo{HMRC (Valuation Office Agency)}{../../../images/voa}$\sqbig$scala engineer}
    {London}
    {Nov 2015 - May 2016}
    {}
    %{At the VOA, a government agency responsible for setting and enforcing tax rates for private and business properties across the UK, I led the redesign of the UI and data input processing, integrating data flows with legacy back-end systems.}
    {
        Architected and delivered an akka-streams wrapper for a legacy web application, securing stakeholder approval for the design.
    %\item{Delivered a government-compliant solution that provided a nationwide platform for council tax and business rates collection.}
    }

%---------------------------------------------------------
    \cventry
    {\tagx{akka-streams} \tagx{play} \tagx{rabbitmq}}
    {\logo{Home Office (Border Force)}{../../../images/ho}$\sqbig$java\,|\,scala engineer}
    {London}
    {Mar 2014 - Oct 2015}
    {}
    %{Border Force is a government agency responsible for securing the UK borders. I created a real-time flight arrival prediction system to forecast airport queue times and staff requirements at the gates.}
    {
        Built a flight arrival prediction engine and incorporated resiliency and recovery processes using akka and rabbitmq.
    %\item{Designed and implemented internal tools for case worker application management using play.}
    }

%---------------------------------------------------------
    \cventry
    {full stack java/scala engineer}
    {\logo{Capco}{../../../images/capco}}
    {London}
    {Sep 2013 - Dec 2013}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {full stack jee/grails engineer}
    {\logo{News UK (News International)}{../../../images/newsuk}}
    {London}
    {Nov 2012 - June 2013}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {full stack jee/grails engineer}
    {\logo{HappyInc Ltd {\textit (now Blow Ltd)}}{../../../images/blowltd}}
    {London}
    {Jul 2012 - Sep 2012}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {full stack jee/grails engineer}
    {\logo{BSkyB (Sky Group)}{../../../images/sky}}
    {London}
    {Aug 2011 - June 2012}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {senior jee engineer}
    {\logo{DMC Digital}{../../../images/dealchecker}}
    {London}
    {Dec 2010 - Jul 2011}
    {}
    {}

%---------------------------------------------------------
    \cventry
    {senior jee engineer}
    {\logo{ITHR}{../../../images/ithr}}
    {London}
    {Oct 2010 - Nov 2010}
    {}
    {}
\end{cventries}
